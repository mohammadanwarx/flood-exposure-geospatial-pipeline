{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd13ead5",
   "metadata": {},
   "source": [
    "# Data Cubes & Tensors Demonstration\n",
    "\n",
    "## Computational Geospatial Analysis - Multi-Dimensional Data Processing\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Section 1: Raster Data Cubes (Xarray)** - Loading, exploring, and analyzing spatio-temporal rainfall data cubes\n",
    "2. **Section 2: Raster Cube + Vector Interaction** - Computing zonal statistics using GeoPandas\n",
    "3. **Section 3: Tensor Operations (PyTorch)** - Converting rasters to tensors and applying convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4bfce1",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: Raster Data Cubes (Xarray)\n",
    "---\n",
    "\n",
    "## 1.1 Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c8eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Setup path and imports\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box, Polygon\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import from src modules\n",
    "from _02_processing.cubes import GeospatialCube, create_flood_cube\n",
    "from _02_processing.tensors import (\n",
    "    create_geospatial_tensor, \n",
    "    normalize_tensor, \n",
    "    apply_convolution,\n",
    "    calculate_tensor_statistics\n",
    ")\n",
    "\n",
    "# PyTorch for tensor operations\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7c9f5",
   "metadata": {},
   "source": [
    "## 1.2 Load Rainfall Data Cube\n",
    "\n",
    "Load the rainfall datacube as an `xarray.Dataset` with explicit dimensions: **time**, **latitude**, **longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load file: [Errno -51] NetCDF: Unknown file format: 'd:\\\\Master\\\\Q2\\\\sci Programming for Geospatial\\\\Project 2\\\\flood-exposure-geospatial-pipeline\\\\data\\\\processed\\\\rainfall_datacube_aoi.nc'\n",
      "Creating synthetic rainfall datacube for demonstration...\n",
      "Synthetic datacube created successfully\n",
      "\n",
      "RAINFALL DATA CUBE STRUCTURE\n",
      "<xarray.Dataset> Size: 2MB\n",
      "Dimensions:        (time: 84, latitude: 50, longitude: 50)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[us] 672B 2018-01-01 ... 2024-12-01\n",
      "  * latitude       (latitude) float64 400B 15.5 15.52 15.53 ... 16.27 16.28 16.3\n",
      "  * longitude      (longitude) float64 400B 32.4 32.42 32.43 ... 33.18 33.2\n",
      "Data variables:\n",
      "    precipitation  (time, latitude, longitude) float64 2MB 27.6 28.81 ... 38.38\n",
      "\n",
      "Dimensions: {'time': 84, 'latitude': 50, 'longitude': 50}\n",
      "\n",
      "Coordinates:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'f' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m rainfall_cube.coords:\n\u001b[32m     40\u001b[39m     vals = rainfall_cube.coords[coord].values\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoord\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvals.min()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvals.max()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mData variables:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m rainfall_cube.data_vars:\n",
      "\u001b[31mValueError\u001b[39m: Unknown format code 'f' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "# Load rainfall datacube from netCDF (with fallback to synthetic data)\n",
    "rainfall_path = '../data/processed/rainfall_datacube_aoi.nc'\n",
    "\n",
    "try:\n",
    "    rainfall_cube = xr.open_dataset(rainfall_path, engine='netcdf4')\n",
    "    print(f\"Loaded rainfall data from: {rainfall_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load file: {e}\")\n",
    "    print(\"Creating synthetic rainfall datacube for demonstration...\")\n",
    "    \n",
    "    # Create synthetic spatio-temporal rainfall data\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    time_steps = 84  # 7 years monthly\n",
    "    lat_size, lon_size = 50, 50\n",
    "    \n",
    "    # Generate realistic rainfall patterns\n",
    "    base_rainfall = np.random.gamma(shape=2, scale=15, size=(time_steps, lat_size, lon_size))\n",
    "    rainfall_values = gaussian_filter(base_rainfall, sigma=1.5)\n",
    "    \n",
    "    # Create xarray Dataset\n",
    "    time = pd.date_range('2018-01-01', periods=time_steps, freq='MS')\n",
    "    lat = np.linspace(15.5, 16.3, lat_size)\n",
    "    lon = np.linspace(32.4, 33.2, lon_size)\n",
    "    \n",
    "    rainfall_cube = xr.Dataset(\n",
    "        {'precipitation': (['time', 'latitude', 'longitude'], rainfall_values)},\n",
    "        coords={'time': time, 'latitude': lat, 'longitude': lon}\n",
    "    )\n",
    "    print(\"Synthetic datacube created successfully\")\n",
    "\n",
    "# Display dataset structure\n",
    "print(\"\\nRAINFALL DATA CUBE STRUCTURE\")\n",
    "print(rainfall_cube)\n",
    "\n",
    "print(\"\\nDimensions:\", dict(rainfall_cube.dims))\n",
    "print(\"\\nCoordinates:\")\n",
    "for coord in rainfall_cube.coords:\n",
    "    vals = rainfall_cube.coords[coord].values\n",
    "    if np.issubdtype(vals.dtype, np.datetime64):\n",
    "        print(f\"  {coord}: [{vals.min()}, {vals.max()}]\")\n",
    "    else:\n",
    "        print(f\"  {coord}: [{vals.min():.4f}, {vals.max():.4f}]\")\n",
    "\n",
    "print(\"\\nData variables:\")\n",
    "for var in rainfall_cube.data_vars:\n",
    "    print(f\"  {var}: {rainfall_cube[var].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838950d",
   "metadata": {},
   "source": [
    "## 1.3 Temporal Aggregations\n",
    "\n",
    "Demonstrate key temporal operations on the data cube:\n",
    "1. **Mean rainfall** - Average precipitation over time\n",
    "2. **Extreme rainfall (95th percentile)** - High-intensity events\n",
    "3. **Coefficient of Variation** - Rainfall variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precipitation variable\n",
    "precip_var = list(rainfall_cube.data_vars)[0]\n",
    "precip = rainfall_cube[precip_var]\n",
    "\n",
    "# 1. Mean rainfall (temporal average)\n",
    "mean_rainfall = precip.mean(dim='time')\n",
    "print(f\"Mean Rainfall: shape={mean_rainfall.shape}, range=[{float(mean_rainfall.min()):.2f}, {float(mean_rainfall.max()):.2f}] mm\")\n",
    "\n",
    "# 2. Extreme rainfall (95th percentile)\n",
    "extreme_rainfall = precip.quantile(0.95, dim='time')\n",
    "print(f\"95th Percentile: shape={extreme_rainfall.shape}, range=[{float(extreme_rainfall.min()):.2f}, {float(extreme_rainfall.max()):.2f}] mm\")\n",
    "\n",
    "# 3. Coefficient of Variation (std/mean)\n",
    "std_rainfall = precip.std(dim='time')\n",
    "cv_rainfall = std_rainfall / (mean_rainfall + 1e-8)\n",
    "print(f\"CV: shape={cv_rainfall.shape}, range=[{float(cv_rainfall.min()):.2f}, {float(cv_rainfall.max()):.2f}]\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "im1 = axes[0].imshow(mean_rainfall.values, cmap='Blues', origin='lower')\n",
    "axes[0].set_title('Mean Rainfall (mm)', fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "\n",
    "im2 = axes[1].imshow(extreme_rainfall.values, cmap='YlOrRd', origin='lower')\n",
    "axes[1].set_title('95th Percentile Rainfall (mm)', fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "im3 = axes[2].imshow(cv_rainfall.values, cmap='viridis', origin='lower')\n",
    "axes[2].set_title('Coefficient of Variation', fontweight='bold')\n",
    "plt.colorbar(im3, ax=axes[2], shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc10553",
   "metadata": {},
   "source": [
    "## 1.4 Spatio-Temporal Slicing\n",
    "\n",
    "Demonstrate slicing operations:\n",
    "1. **Single year extraction** - One year of data\n",
    "2. **Multi-year comparison** - Compare different time periods\n",
    "3. **Spatial subsetting** - Extract a region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ed5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time range\n",
    "time_coords = pd.to_datetime(precip.time.values)\n",
    "print(f\"Full time range: {time_coords.min()} to {time_coords.max()}\")\n",
    "\n",
    "# 1. Single year (2019)\n",
    "precip_2019 = precip.sel(time=slice('2019-01-01', '2019-12-31'))\n",
    "print(f\"2019 slice: {precip_2019.shape}, mean={float(precip_2019.mean()):.2f} mm\")\n",
    "\n",
    "# 2. Multi-year (2018-2020)\n",
    "precip_multi = precip.sel(time=slice('2018-01-01', '2020-12-31'))\n",
    "print(f\"2018-2020 slice: {precip_multi.shape}, mean={float(precip_multi.mean()):.2f} mm\")\n",
    "\n",
    "# 3. Spatial subset\n",
    "lat_dim = 'latitude' if 'latitude' in precip.coords else 'lat'\n",
    "lon_dim = 'longitude' if 'longitude' in precip.coords else 'lon'\n",
    "lat_coords = precip[lat_dim].values\n",
    "lon_coords = precip[lon_dim].values\n",
    "\n",
    "lat_subset = (lat_coords.min() + (lat_coords.max()-lat_coords.min())*0.25, \n",
    "              lat_coords.min() + (lat_coords.max()-lat_coords.min())*0.75)\n",
    "lon_subset = (lon_coords.min() + (lon_coords.max()-lon_coords.min())*0.25,\n",
    "              lon_coords.min() + (lon_coords.max()-lon_coords.min())*0.75)\n",
    "\n",
    "precip_spatial = precip.sel({lat_dim: slice(*lat_subset), lon_dim: slice(*lon_subset)})\n",
    "print(f\"Spatial subset: {precip.shape} -> {precip_spatial.shape}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "im1 = axes[0].imshow(precip_2019.mean(dim='time').values, cmap='Blues', origin='lower')\n",
    "axes[0].set_title('Mean Rainfall 2019', fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0], shrink=0.8, label='mm')\n",
    "\n",
    "im2 = axes[1].imshow(precip_multi.mean(dim='time').values, cmap='Blues', origin='lower')\n",
    "axes[1].set_title('Mean Rainfall 2018-2020', fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[1], shrink=0.8, label='mm')\n",
    "\n",
    "im3 = axes[2].imshow(precip_spatial.mean(dim='time').values, cmap='Blues', origin='lower')\n",
    "axes[2].set_title('Spatial Subset (Central Region)', fontweight='bold')\n",
    "plt.colorbar(im3, ax=axes[2], shrink=0.8, label='mm')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624812b5",
   "metadata": {},
   "source": [
    "## 1.5 Time Series Analysis\n",
    "\n",
    "Visualize rainfall trends over time through aggregation along spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d12c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial aggregation - time series\n",
    "spatial_dims = [lat_dim, lon_dim]\n",
    "time_series_mean = precip.mean(dim=spatial_dims)\n",
    "time_series_max = precip.max(dim=spatial_dims)\n",
    "\n",
    "print(f\"Time series: {len(time_series_mean)} values, mean={float(time_series_mean.mean()):.2f} mm\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(time_series_mean.time, time_series_mean.values, linewidth=2, color='steelblue')\n",
    "axes[0].fill_between(time_series_mean.time.values, 0, time_series_mean.values, alpha=0.3)\n",
    "axes[0].set_ylabel('Precipitation (mm)')\n",
    "axes[0].set_title('Mean Rainfall Over Time (Spatial Average)', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(time_series_max.time, time_series_max.values, linewidth=2, color='indianred')\n",
    "axes[1].fill_between(time_series_max.time.values, 0, time_series_max.values, alpha=0.3)\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Precipitation (mm)')\n",
    "axes[1].set_title('Maximum Rainfall Over Time (Extreme Events)', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87c1c3",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Raster Cube + Vector Interaction\n",
    "---\n",
    "\n",
    "## 2.1 Zonal Statistics with GeoPandas\n",
    "\n",
    "Compute mean rainfall per polygon zone using the data cube + vector integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b089b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4 quadrant zones for zonal statistics\n",
    "lat_coords = precip[lat_dim].values\n",
    "lon_coords = precip[lon_dim].values\n",
    "lat_mid = (lat_coords.min() + lat_coords.max()) / 2\n",
    "lon_mid = (lon_coords.min() + lon_coords.max()) / 2\n",
    "\n",
    "zones = gpd.GeoDataFrame({\n",
    "    'zone_id': ['NW', 'NE', 'SW', 'SE'],\n",
    "    'zone_name': ['Northwest', 'Northeast', 'Southwest', 'Southeast'],\n",
    "    'geometry': [\n",
    "        box(lon_coords.min(), lat_mid, lon_mid, lat_coords.max()),\n",
    "        box(lon_mid, lat_mid, lon_coords.max(), lat_coords.max()),\n",
    "        box(lon_coords.min(), lat_coords.min(), lon_mid, lat_mid),\n",
    "        box(lon_mid, lat_coords.min(), lon_coords.max(), lat_mid),\n",
    "    ]\n",
    "}, crs=\"EPSG:4326\")\n",
    "\n",
    "# Compute zonal statistics\n",
    "mean_precip = precip.mean(dim='time')\n",
    "\n",
    "def compute_zonal_mean(raster_data, zones_gdf, lat_coords, lon_coords):\n",
    "    results = []\n",
    "    for idx, zone in zones_gdf.iterrows():\n",
    "        minx, miny, maxx, maxy = zone.geometry.bounds\n",
    "        lat_mask = (lat_coords >= miny) & (lat_coords <= maxy)\n",
    "        lon_mask = (lon_coords >= minx) & (lon_coords <= maxx)\n",
    "        zone_values = raster_data.values[np.ix_(lat_mask, lon_mask)]\n",
    "        results.append({\n",
    "            'zone_id': zone['zone_id'], 'zone_name': zone['zone_name'],\n",
    "            'mean_rainfall': float(np.nanmean(zone_values)),\n",
    "            'max_rainfall': float(np.nanmax(zone_values)),\n",
    "            'pixel_count': zone_values.size\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "zonal_stats = compute_zonal_mean(mean_precip, zones, lat_coords, lon_coords)\n",
    "zones = zones.merge(zonal_stats, on=['zone_id', 'zone_name'])\n",
    "\n",
    "print(\"Zonal Statistics:\")\n",
    "print(zonal_stats.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "im1 = axes[0].imshow(mean_precip.values, cmap='Blues', origin='lower',\n",
    "                     extent=[lon_coords.min(), lon_coords.max(), lat_coords.min(), lat_coords.max()])\n",
    "zones.boundary.plot(ax=axes[0], color='red', linewidth=2)\n",
    "for idx, row in zones.iterrows():\n",
    "    axes[0].annotate(row['zone_id'], (row.geometry.centroid.x, row.geometry.centroid.y), \n",
    "                    fontsize=14, fontweight='bold', color='red', ha='center', va='center')\n",
    "axes[0].set_title('Mean Rainfall with Analysis Zones', fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0], label='mm', shrink=0.8)\n",
    "\n",
    "bars = axes[1].bar(zones['zone_name'], zones['mean_rainfall'], \n",
    "                   color=plt.cm.Blues(np.linspace(0.4, 0.9, len(zones))), edgecolor='navy')\n",
    "axes[1].set_ylabel('Mean Rainfall (mm)')\n",
    "axes[1].set_title('Mean Rainfall by Zone', fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "for bar, val in zip(bars, zones['mean_rainfall']):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{val:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf6f5e",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: Tensor Operations (PyTorch)\n",
    "---\n",
    "\n",
    "## 3.1 Convert Raster to Tensor\n",
    "\n",
    "Demonstrate the pipeline: **Raster → NumPy → Tensor → Operation → NumPy**\n",
    "\n",
    "Using functions from `src/_02_processing/tensors.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Raster -> NumPy arrays\n",
    "numpy_mean = mean_rainfall.values.astype(np.float32)\n",
    "numpy_extreme = extreme_rainfall.values.astype(np.float32)\n",
    "numpy_cv = cv_rainfall.values.astype(np.float32)\n",
    "\n",
    "print(\"Pipeline: Raster -> NumPy -> Tensor -> Operation -> NumPy\")\n",
    "print(f\"Input arrays: {numpy_mean.shape}, dtype={numpy_mean.dtype}\")\n",
    "\n",
    "# Step 2: Create multi-band tensor\n",
    "geo_tensor = create_geospatial_tensor([numpy_mean, numpy_extreme, numpy_cv])\n",
    "print(f\"Tensor created: {geo_tensor.shape} (bands, height, width)\")\n",
    "\n",
    "# Step 3: Normalize tensor\n",
    "tensor_normalized = normalize_tensor(geo_tensor, method='minmax')\n",
    "print(f\"Normalized: [{tensor_normalized.min():.4f}, {tensor_normalized.max():.4f}]\")\n",
    "\n",
    "# Step 4: Calculate statistics\n",
    "stats = calculate_tensor_statistics(tensor_normalized)\n",
    "print(\"\\nTensor Statistics:\")\n",
    "for band_name, s in stats.items():\n",
    "    print(f\"  {band_name}: mean={s['mean']:.4f}, std={s['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45061768",
   "metadata": {},
   "source": [
    "## 3.2 Convolution Operation\n",
    "\n",
    "Apply spatial convolution to simulate influence spread / smoothing.\n",
    "\n",
    "This is a meaningful geospatial operation - convolution spreads values to neighboring cells, simulating how phenomena like flooding spread spatially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convolution kernels\n",
    "avg_kernel = np.ones((3, 3), dtype=np.float32) / 9.0\n",
    "gaussian_kernel = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]], dtype=np.float32) / 16.0\n",
    "\n",
    "print(\"Averaging Kernel (3x3):\\n\", avg_kernel)\n",
    "print(\"\\nGaussian Kernel (3x3):\\n\", gaussian_kernel)\n",
    "\n",
    "# Apply convolution using src function\n",
    "input_band = tensor_normalized[0:1]\n",
    "convolved_avg = apply_convolution(input_band, avg_kernel)\n",
    "convolved_gaussian = apply_convolution(input_band, gaussian_kernel)\n",
    "\n",
    "print(f\"\\nConvolution applied: {input_band.shape} -> {convolved_avg.shape}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "im1 = axes[0].imshow(input_band[0], cmap='Blues', origin='lower')\n",
    "axes[0].set_title('Original (Normalized Mean Rainfall)', fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "\n",
    "im2 = axes[1].imshow(convolved_avg[0], cmap='Blues', origin='lower')\n",
    "axes[1].set_title('After Averaging Convolution', fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "im3 = axes[2].imshow(convolved_gaussian[0], cmap='Blues', origin='lower')\n",
    "axes[2].set_title('After Gaussian Convolution', fontweight='bold')\n",
    "plt.colorbar(im3, ax=axes[2], shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39996614",
   "metadata": {},
   "source": [
    "## 3.3 PyTorch Tensor Operations\n",
    "\n",
    "Demonstrate native PyTorch tensor operations with GPU awareness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaef5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy to PyTorch tensor\n",
    "torch_tensor = torch.from_numpy(tensor_normalized).float()\n",
    "print(f\"PyTorch tensor: {torch_tensor.shape}, dtype={torch_tensor.dtype}, device={torch_tensor.device}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# PyTorch convolution\n",
    "input_4d = torch_tensor.unsqueeze(0)  # Add batch dimension: (1, C, H, W)\n",
    "kernel_torch = torch.ones(1, 1, 3, 3) / 9.0\n",
    "\n",
    "first_channel = input_4d[:, 0:1, :, :]\n",
    "convolved_torch = F.conv2d(first_channel, kernel_torch, padding=1)\n",
    "result_numpy = convolved_torch.squeeze().numpy()\n",
    "\n",
    "print(f\"Conv2d: {first_channel.shape} -> {convolved_torch.shape} -> NumPy {result_numpy.shape}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "im1 = axes[0].imshow(torch_tensor[0].numpy(), cmap='Blues', origin='lower')\n",
    "axes[0].set_title('Original (PyTorch Tensor)', fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "\n",
    "im2 = axes[1].imshow(result_numpy, cmap='Blues', origin='lower')\n",
    "axes[1].set_title('After PyTorch F.conv2d', fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPipeline complete: Raster -> NumPy -> Tensor -> Convolution -> NumPy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cff63",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "---\n",
    "\n",
    "## What was demonstrated:\n",
    "\n",
    "### Section 1: Raster Data Cubes (Xarray)\n",
    "- Loaded rainfall data cube as `xarray.Dataset`\n",
    "- Explicit dimensions: **time**, **latitude**, **longitude**\n",
    "- **Temporal aggregations**: mean, 95th percentile, coefficient of variation\n",
    "- **Spatio-temporal slicing**: single year, multi-year, spatial subset\n",
    "- Time series visualization from spatial aggregation\n",
    "\n",
    "### Section 2: Raster Cube + Vector Interaction\n",
    "- Created polygon zones (representing administrative units)\n",
    "- Computed **zonal statistics**: mean, max, min, std rainfall per zone\n",
    "- Demonstrated **cube → vector** integration using GeoPandas\n",
    "\n",
    "### Section 3: Tensor Operations (PyTorch)\n",
    "- Converted raster data to multi-band tensor using `create_geospatial_tensor()`\n",
    "- Normalized tensor using `normalize_tensor()`\n",
    "- Calculated statistics using `calculate_tensor_statistics()`\n",
    "- Applied **convolution** using `apply_convolution()` (spatial influence spread)\n",
    "- Demonstrated PyTorch native operations with GPU awareness\n",
    "- Complete pipeline: **Raster → NumPy → Tensor → Operation → NumPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f4d2c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
